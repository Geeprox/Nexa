# PRD V2: 设置页与 LLM API 配置

## 文档目标
定义 V2 设置页能力边界，确保用户可通过侧栏 `设置` 入口进入独立页面并完成模型 API 相关配置。

## 背景
V1 已将侧栏底部收敛为单一 `设置` 入口。为支撑真实模型接入，V2 需要补齐配置页，统一管理 API Key、Base URL、模型分层与调用策略。

## 产品目标
1. 点击侧栏 `设置` 可进入设置页面。
2. 用户可配置并保存 LLM API 连接参数。
3. 支持高/中/低模型分层映射配置。
4. 配置需可校验、可测试连接、可安全持久化。
5. 配置变更不破坏现有会话数据。

## 非目标
1. V2 不实现云端账号同步。
2. V2 不实现团队级密钥管理。
3. V2 不实现计费面板。

## 用户故事
- 我希望在本地桌面应用中直接设置 API Key 和 API Endpoint。
- 我希望能分别指定高/中/低层模型，方便不同任务调用。
- 我希望在保存前先验证配置是否可用，避免运行时才失败。

## 功能需求
### FR-SET-001 设置入口
- 侧栏 `设置` 按钮跳转到设置页。
- 若设置页未完成关键配置，显示引导状态。

### FR-SET-002 基础 API 配置
- 字段至少包括：
  - Provider（默认 OpenAI 兼容）
  - Base URL
  - API Key
  - Organization / Project（可选）
- API Key 支持掩码展示与显隐切换。

### FR-SET-003 模型分层配置
- 高/中/低三个档位可分别配置模型 ID。
- 每档支持设置默认温度、最大 token（可选）。

### FR-SET-004 连接测试
- 用户可点击“测试连接”。
- 返回成功/失败与可读错误信息。

### FR-SET-005 安全与持久化
- 配置持久化到本地存储。
- API Key 不写入日志明文。
- 提供“重置为默认”能力。

### FR-SET-006 运行时接入
- 聊天调用真实 LLM 时从设置页配置读取参数。
- 缺失关键配置时，调用层返回明确引导错误。

## 非功能需求
1. 可用性
- 表单校验需在输入阶段给出即时反馈。
2. 安全性
- API Key 在 UI 与日志中默认脱敏。
3. 性能
- 设置页加载时间 < 300ms（本地）。
4. 质量
- 新增测试并保持覆盖率 >= 80%。

## 验收标准
1. 点击 `设置` 能稳定进入设置页。
2. 填写并保存后重启应用，配置可恢复。
3. 连接测试失败时可得到明确错误提示。
4. 模型分层配置可被调用层读取并生效。

## 风险
1. 不同 Provider 兼容字段差异大。
2. API Key 本地存储安全策略需谨慎。

## 缓解
1. V2 首版采用 OpenAI-compatible 统一字段，Provider 扩展后置。
2. 先实现最小可用安全策略（脱敏、日志隔离、最小暴露面）。

## 依赖
- `src/lib/llm/*` 路由与 provider 抽象。
- 本地配置存储模块（Web localStorage / Tauri secure storage 评估）。
